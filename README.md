# ğŸ§  AI x DevOps Project â€“ Scalable Infra for LLM-Powered Apps

This project shows how to build secure, scalable, cost-aware infrastructure for AI-native tools using modern DevOps practices.

Instead of treating AI apps like demos, this project treats them like real software â€” with versioning, token usage tracking, CI/CD, and containerized deployment.

---

## ğŸ”§ Features

- âœ… **FastAPI app** for handling LLM-style prompts
- âœ… **Prompt versioning** with SHA hash
- âœ… **Token usage logging** to CSV
- âœ… **Dockerized workflow**
- âœ… **CI/CD with GitHub Actions**
- ğŸ”’ **Vault for secrets management** (planned)
- â˜ï¸ **AKS deployment** (planned)

---

## ğŸ“ Project Structure

ai-devops-pipeline/
â”œâ”€â”€ app/
â”‚ â””â”€â”€ main.py
â”œâ”€â”€ prompts/
â”œâ”€â”€ logs/
â”œâ”€â”€ scripts/
â”œâ”€â”€ .github/workflows/
â”‚ â””â”€â”€ deploy.yml
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md

yaml
Copy
Edit


---

## ğŸš€ Quick Start (Local)

```bash
# Clone the repo
git clone https://github.com/MichaelObasa/ai-devops-pipeline.git
cd ai-devops-pipeline

# Build the container
docker build -t ai-devops-app .

# Run the container
docker run -p 8000:8000 ai-devops-app

# Test with curl
curl -X POST http://localhost:8000/prompt \
  -H "Content-Type: application/json" \
  -d '{"prompt": "What is DevOps?"}'

{
  "version_id": "a1b2c3d4",
  "response": "Mock GPT response to: What is DevOps?",
  "tokens_used": 10
}


